{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb9fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 5465 nodes and 4991 edges\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "random.seed(4)\n",
    "# Reducing the size of the network\n",
    "\n",
    "df_edges = pd.read_csv(\"com-Amazon.csv\", delimiter = \" \")\n",
    "OG = nx.from_pandas_edgelist(df_edges, source=\"From\", target=\"To\", create_using= nx.DiGraph) #the original co-purchasing network\n",
    "edges = random.sample(list(OG.nodes()), int(OG.number_of_nodes() * 0.26)) # will use only 25% of the graph\n",
    "G=OG.subgraph(edges)\n",
    "largest_cc = max(nx.weakly_connected_components(G), key=len) #find the largest weakly component\n",
    "G1=G.subgraph(largest_cc) # the final graph with the largest weakly connected component\n",
    "G2= G1.to_undirected()\n",
    "G2_node_list= [] # add node that have the degree > 2\n",
    "for node,degree in G1.degree():\n",
    "    if degree > 2:\n",
    "        G2_node_list.append(node)\n",
    "G2= G1.subgraph(G2_node_list) #creating the graph base on the degree > 2\n",
    "        \n",
    "removed_edges = random.sample(list(G2.edges()), int(G2.number_of_edges() * 0.30)) #we will removed 20% of the edges\n",
    "G_train = G2.copy()\n",
    "G_train.remove_edges_from(removed_edges)\n",
    "G_test = G2.copy()\n",
    "#G_test.add_edges_from(removed_edges)\n",
    "\n",
    "G_train=G_train.to_undirected()\n",
    "print(G_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09175ccf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For JA \n",
      "for 10, the number of correct edges being predicted 1 and the rate of it is 0.1\n",
      "for 20, the number of correct edges being predicted 2 and the rate of it is 0.1\n",
      "for 30, the number of correct edges being predicted 2 and the rate of it is 0.06666666666666667\n",
      "for 40, the number of correct edges being predicted 3 and the rate of it is 0.075\n",
      "for 50, the number of correct edges being predicted 4 and the rate of it is 0.08\n",
      "for 60, the number of correct edges being predicted 7 and the rate of it is 0.11666666666666667\n",
      "for 70, the number of correct edges being predicted 7 and the rate of it is 0.1\n",
      "for 80, the number of correct edges being predicted 8 and the rate of it is 0.1\n",
      "for 90, the number of correct edges being predicted 10 and the rate of it is 0.1111111111111111\n",
      "for 100, the number of correct edges being predicted 11 and the rate of it is 0.11\n",
      "for 110, the number of correct edges being predicted 11 and the rate of it is 0.1\n",
      "for 120, the number of correct edges being predicted 12 and the rate of it is 0.1\n",
      "for 130, the number of correct edges being predicted 14 and the rate of it is 0.1076923076923077\n",
      "for 140, the number of correct edges being predicted 15 and the rate of it is 0.10714285714285714\n",
      "for 150, the number of correct edges being predicted 15 and the rate of it is 0.1\n",
      "for 160, the number of correct edges being predicted 16 and the rate of it is 0.1\n",
      "for 170, the number of correct edges being predicted 18 and the rate of it is 0.10588235294117647\n",
      "for 180, the number of correct edges being predicted 18 and the rate of it is 0.1\n",
      "for 190, the number of correct edges being predicted 20 and the rate of it is 0.10526315789473684\n",
      "for 200, the number of correct edges being predicted 22 and the rate of it is 0.11\n",
      "for 210, the number of correct edges being predicted 22 and the rate of it is 0.10476190476190476\n",
      "for 220, the number of correct edges being predicted 23 and the rate of it is 0.10454545454545454\n",
      "for 230, the number of correct edges being predicted 23 and the rate of it is 0.1\n",
      "for 240, the number of correct edges being predicted 24 and the rate of it is 0.1\n",
      "for 250, the number of correct edges being predicted 25 and the rate of it is 0.1\n",
      "for 260, the number of correct edges being predicted 26 and the rate of it is 0.1\n",
      "for 270, the number of correct edges being predicted 26 and the rate of it is 0.0962962962962963\n",
      "for 280, the number of correct edges being predicted 26 and the rate of it is 0.09285714285714286\n",
      "for 290, the number of correct edges being predicted 26 and the rate of it is 0.0896551724137931\n",
      "for 300, the number of correct edges being predicted 28 and the rate of it is 0.09333333333333334\n",
      "For AA \n",
      "for 10, the number of correct edges being predicted 1 and the rate of it is 0.1\n",
      "for 20, the number of correct edges being predicted 2 and the rate of it is 0.1\n",
      "for 30, the number of correct edges being predicted 5 and the rate of it is 0.16666666666666666\n",
      "for 40, the number of correct edges being predicted 9 and the rate of it is 0.225\n",
      "for 50, the number of correct edges being predicted 10 and the rate of it is 0.2\n",
      "for 60, the number of correct edges being predicted 12 and the rate of it is 0.2\n",
      "for 70, the number of correct edges being predicted 16 and the rate of it is 0.22857142857142856\n",
      "for 80, the number of correct edges being predicted 17 and the rate of it is 0.2125\n",
      "for 90, the number of correct edges being predicted 17 and the rate of it is 0.18888888888888888\n",
      "for 100, the number of correct edges being predicted 19 and the rate of it is 0.19\n",
      "for 110, the number of correct edges being predicted 20 and the rate of it is 0.18181818181818182\n",
      "for 120, the number of correct edges being predicted 21 and the rate of it is 0.175\n",
      "for 130, the number of correct edges being predicted 22 and the rate of it is 0.16923076923076924\n",
      "for 140, the number of correct edges being predicted 23 and the rate of it is 0.16428571428571428\n",
      "for 150, the number of correct edges being predicted 27 and the rate of it is 0.18\n",
      "for 160, the number of correct edges being predicted 29 and the rate of it is 0.18125\n",
      "for 170, the number of correct edges being predicted 29 and the rate of it is 0.17058823529411765\n",
      "for 180, the number of correct edges being predicted 29 and the rate of it is 0.16111111111111112\n",
      "for 190, the number of correct edges being predicted 30 and the rate of it is 0.15789473684210525\n",
      "for 200, the number of correct edges being predicted 31 and the rate of it is 0.155\n",
      "for 210, the number of correct edges being predicted 34 and the rate of it is 0.1619047619047619\n",
      "for 220, the number of correct edges being predicted 37 and the rate of it is 0.16818181818181818\n",
      "for 230, the number of correct edges being predicted 41 and the rate of it is 0.1782608695652174\n",
      "for 240, the number of correct edges being predicted 42 and the rate of it is 0.175\n",
      "for 250, the number of correct edges being predicted 42 and the rate of it is 0.168\n",
      "for 260, the number of correct edges being predicted 42 and the rate of it is 0.16153846153846155\n",
      "for 270, the number of correct edges being predicted 43 and the rate of it is 0.15925925925925927\n",
      "for 280, the number of correct edges being predicted 44 and the rate of it is 0.15714285714285714\n",
      "for 290, the number of correct edges being predicted 44 and the rate of it is 0.15172413793103448\n",
      "for 300, the number of correct edges being predicted 45 and the rate of it is 0.15\n",
      "For PA \n",
      "for 10, the number of correct edges being predicted 1 and the rate of it is 0.1\n",
      "for 20, the number of correct edges being predicted 1 and the rate of it is 0.05\n",
      "for 30, the number of correct edges being predicted 1 and the rate of it is 0.03333333333333333\n",
      "for 40, the number of correct edges being predicted 1 and the rate of it is 0.025\n",
      "for 50, the number of correct edges being predicted 1 and the rate of it is 0.02\n",
      "for 60, the number of correct edges being predicted 1 and the rate of it is 0.016666666666666666\n",
      "for 70, the number of correct edges being predicted 1 and the rate of it is 0.014285714285714285\n",
      "for 80, the number of correct edges being predicted 1 and the rate of it is 0.0125\n",
      "for 90, the number of correct edges being predicted 1 and the rate of it is 0.011111111111111112\n",
      "for 100, the number of correct edges being predicted 1 and the rate of it is 0.01\n",
      "for 110, the number of correct edges being predicted 1 and the rate of it is 0.00909090909090909\n",
      "for 120, the number of correct edges being predicted 1 and the rate of it is 0.008333333333333333\n",
      "for 130, the number of correct edges being predicted 1 and the rate of it is 0.007692307692307693\n",
      "for 140, the number of correct edges being predicted 1 and the rate of it is 0.007142857142857143\n",
      "for 150, the number of correct edges being predicted 1 and the rate of it is 0.006666666666666667\n",
      "for 160, the number of correct edges being predicted 1 and the rate of it is 0.00625\n",
      "for 170, the number of correct edges being predicted 1 and the rate of it is 0.0058823529411764705\n",
      "for 180, the number of correct edges being predicted 1 and the rate of it is 0.005555555555555556\n",
      "for 190, the number of correct edges being predicted 1 and the rate of it is 0.005263157894736842\n",
      "for 200, the number of correct edges being predicted 1 and the rate of it is 0.005\n",
      "for 210, the number of correct edges being predicted 1 and the rate of it is 0.004761904761904762\n",
      "for 220, the number of correct edges being predicted 1 and the rate of it is 0.004545454545454545\n",
      "for 230, the number of correct edges being predicted 1 and the rate of it is 0.004347826086956522\n",
      "for 240, the number of correct edges being predicted 1 and the rate of it is 0.004166666666666667\n",
      "for 250, the number of correct edges being predicted 1 and the rate of it is 0.004\n",
      "for 260, the number of correct edges being predicted 1 and the rate of it is 0.0038461538461538464\n",
      "for 270, the number of correct edges being predicted 1 and the rate of it is 0.003703703703703704\n",
      "for 280, the number of correct edges being predicted 1 and the rate of it is 0.0035714285714285713\n",
      "for 290, the number of correct edges being predicted 1 and the rate of it is 0.0034482758620689655\n",
      "for 300, the number of correct edges being predicted 1 and the rate of it is 0.0033333333333333335\n"
     ]
    }
   ],
   "source": [
    "# jacard\n",
    "n_star= np.arange(10,110,10)\n",
    "\n",
    "# Calculating for Jacard value\n",
    "def JA_cal(graph): \n",
    "    jacard = nx.jaccard_coefficient(graph)\n",
    "    jacard_pred = []\n",
    "    for u, v, p in jacard:\n",
    "        jacard_pred.append([u, v, p])\n",
    "    jacard_pred = pd.DataFrame(jacard_pred, columns=['u', 'v', 'p']) \n",
    "    jacard_pred = jacard_pred.sort_values(by='p', ascending=False)\n",
    "    pred= jacard_pred\n",
    "    return pred\n",
    "\n",
    "# Calculating for Adamic Adar value\n",
    "\n",
    "def AA_cal(graph):\n",
    "    adamic = nx.adamic_adar_index(graph)\n",
    "    adamic_pred = []\n",
    "    for u, v, p in adamic:\n",
    "        adamic_pred.append([u, v, p])\n",
    "    adamic_pred = pd.DataFrame(adamic_pred, columns=['u', 'v', 'p'])\n",
    "    adamic_pred = adamic_pred.sort_values(by='p', ascending=False)\n",
    "    pred= adamic_pred\n",
    "    return pred\n",
    "\n",
    "# Calculating for Preferential attachment value\n",
    "\n",
    "def PA_cal(graph):\n",
    "    pref = nx.preferential_attachment(graph)\n",
    "    PA_prec= []\n",
    "    for u, v, p in pref:\n",
    "        PA_prec.append([u, v, p])\n",
    "    PA_prec = pd.DataFrame(PA_prec, columns=['u', 'v', 'p'])\n",
    "    PA_prec = PA_prec.sort_values(by='p', ascending=False)\n",
    "    pred= PA_prec\n",
    "    return pred\n",
    "\n",
    "# Calculating for Resource Allocation value\n",
    "\n",
    "def RA_cal(graph):\n",
    "    res = nx.resource_allocation_index(graph)\n",
    "    RA_prec= []\n",
    "    for u, v, p in res:\n",
    "        RA_prec.append([u, v, p])\n",
    "    RA_prec = pd.DataFrame(RA_prec, columns=['u', 'v', 'p'])\n",
    "    RA_prec = RA_prec.sort_values(by='p', ascending=False)\n",
    "    pred= RA_prec\n",
    "    return pred\n",
    "\n",
    "# Check to see if all of the link prediction is accurately predicting the value\n",
    "def pred_accuracy(predEdges,removed_edges,k):\n",
    "    correctly_nodes = [value for value in predEdges if value in removed_edges]\n",
    "    number_of_correct= len(correctly_nodes)\n",
    "    rate= number_of_correct/k\n",
    "    return (number_of_correct,rate)\n",
    "    \n",
    "def FinalValue(graph, link):\n",
    "    Ks = np.arange(10,310,10) # starting from 10, start incrementing by 10 -> 10,20,30,...\n",
    "    if link == \"JA\":\n",
    "        pred= JA_cal(graph)\n",
    "    elif link == 'AA':\n",
    "        pred= AA_cal(graph)\n",
    "    elif link == 'PA':\n",
    "        pred= PA_cal(graph)\n",
    "    elif link == 'RA':\n",
    "        pred= RA_cal(graph)\n",
    "\n",
    "    \n",
    "    print(\"For {} \".format(link))\n",
    "    Final_Value= []\n",
    "    for k in Ks:     \n",
    "        predEdges= []\n",
    "        score= []\n",
    "        for i in range(k):\n",
    "            predEdges.append((int(pred.iloc[i]['u']),int(pred.iloc[i]['v'])))\n",
    "            score.append(((pred.iloc[i]['p'])))\n",
    "        result = pred_accuracy(predEdges,removed_edges,k)\n",
    "        Final_Value.append(result)\n",
    "        print(\"for {}, the number of correct edges being predicted {} and the rate of it is {}\".format(k,result[0],result[1]))\n",
    "    return Final_Value\n",
    "FinalValue(G_train, link= \"JA\")\n",
    "FinalValue(G_train, link= \"AA\")\n",
    "FinalValue(G_train, link= \"PA\")\n",
    "FinalValue(G_train, link= \"RA\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b693b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "100\n",
      "105\n",
      "110\n",
      "115\n",
      "120\n",
      "125\n",
      "130\n",
      "135\n",
      "140\n",
      "145\n",
      "150\n",
      "155\n",
      "160\n",
      "165\n",
      "170\n",
      "175\n",
      "180\n",
      "185\n",
      "190\n",
      "195\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "Ks = np.arange(5,205,5)\n",
    "for k in Ks:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_star= np.arange(10,110,10)\n",
    "adamic = nx.adamic_adar_index(G_train)\n",
    "adamic_pred = []\n",
    "for u, v, p in adamic:\n",
    "    adamic_pred.append([u, v, p])\n",
    "\n",
    "adamic_pred = pd.DataFrame(adamic_adar_index, columns=['u', 'v', 'adamic'])\n",
    "\n",
    "for n in n_star:\n",
    "    adamic_pred_n = adamic_pred.sort_values(by='adamic', ascending=False).head(n) #sorting \n",
    "    adamic_pred_new= []\n",
    "    for i in range(len(adamic_pred_n)):\n",
    "        if adamic_pred_n.iloc[i]['adamic'] >= 0.50: # number of predicion \n",
    "            comparing= (int(adamic_pred_n.iloc[i]['u']),int(adamic_pred_n.iloc[i]['v']),(adamic_pred_n.iloc[i]['adamic']))\n",
    "            adamic_pred_new.append(comparing)\n",
    "\n",
    "    \n",
    "    for u, v, p in adamic_pred_new:\n",
    "        success= 0\n",
    "        failure= 0\n",
    "        true=[]\n",
    "        if ((u,v)) in removed_edges:\n",
    "          true.append(p)\n",
    "          print(u,v)\n",
    "          success+=1\n",
    "        else:\n",
    "          failure+=1\n",
    "    print(true)\n",
    "    print(\"The number of success given the top {}* trial is {}\".format(n,success))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4269dcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adamic adar\n",
    "\n",
    "    adamic = nx.adamic_adar_index(graph)\n",
    "    adamic_pred= []\n",
    "    for u, v, p in adamic:\n",
    "        adamic_pred.append([u,v,p])\n",
    "    adamic_pred = pd.DataFrame(adamic_pred, columns=['u', 'v', 'adamic'])\n",
    "    adamic_pred = adamic_pred.sort_values(by='adamic', ascending=False).head(n)\n",
    "    adamic_pred['pred'] = 0\n",
    "    adamic_pred.loc[adamic_pred['adamic'] > 0.15, 'pred'] = 1\n",
    "\n",
    "\n",
    "    pred=[]\n",
    "    for i in range(len(adamic_pred)): \n",
    "        if adamic_pred['pred'][i] == 1: # number of predicion \n",
    "            comparing= (int(adamic_pred.iloc[i]['u']),int(adamic_pred.iloc[i]['v']),(adamic_pred.iloc[i]['adamic']))\n",
    "            pred.append(comparing)\n",
    "    success=0\n",
    "    failure=0\n",
    "    true=[]\n",
    "    for u, v, j in pred:\n",
    "        if ((u,v)) in G_test.edges():\n",
    "          true.append(j)\n",
    "          success+=1\n",
    "        else:\n",
    "          failure+=1\n",
    "    return success\n",
    "\n",
    "adamic(G_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491612ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
